{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 19:32:13.886485: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-04 19:32:13.929634: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-04 19:32:13.930411: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-04 19:32:14.578910: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 80), (1459, 80), (2919, 80), (1460, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "# Removing the sale price column from training data to process training and testing data together\n",
    "df_final_train = pd.DataFrame({'SalePrice':df_train['SalePrice']})\n",
    "df_train = df_train.drop('SalePrice', axis = 1)\n",
    "\n",
    "# Creating a combined dataframe\n",
    "df_combined = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "df_train.shape, df_test.shape, df_combined.shape, df_final_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 79)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing ID column\n",
    "df_combined = df_combined.drop('Id', axis = 1)\n",
    "\n",
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 72)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values\n",
    "percent_na_columns = df_combined.isnull().mean()\n",
    "\n",
    "# Finding the column names of those having missing values greater than 10%\n",
    "missing_columns = percent_na_columns[percent_na_columns>0.1].index\n",
    "\n",
    "df_combined = df_combined.drop(missing_columns, axis = 1)\n",
    "\n",
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling categorical missing data with mode for columns having less null values\n",
    "categorical_columns = df_combined.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "na_sum = df_combined[categorical_columns].isnull().sum()\n",
    "columns_below_threshold = na_sum[na_sum < 20].index\n",
    "columns_above_threshold = pd.Series(na_sum[na_sum >= 20].index)\n",
    "\n",
    "df_combined[columns_below_threshold] = df_combined[columns_below_threshold].fillna(df_combined[columns_below_threshold].mode().iloc[0])\n",
    "\n",
    "# Filling non-categorical missing data with mean for columns having less null values\n",
    "numerical_columns = df_combined.select_dtypes(include=['int', 'float']).columns\n",
    "\n",
    "na_sum = df_combined[numerical_columns].isnull().sum()\n",
    "num_columns_below_threshold = na_sum[na_sum < 20].index\n",
    "num_columns_above_threshold = pd.Series(na_sum[na_sum >= 20].index)\n",
    "\n",
    "df_combined[num_columns_below_threshold] = df_combined[num_columns_below_threshold].fillna(df_combined[num_columns_below_threshold].mean().iloc[0])\n",
    "\n",
    "above_threshold = pd.Index(pd.concat([columns_above_threshold, num_columns_above_threshold], axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>3</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>3</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  MSZoning  LotArea  Street  LotShape  LandContour  Utilities  \\\n",
       "0        60.0         3   8450.0       1         3            3          0   \n",
       "1        20.0         3   9600.0       1         3            3          0   \n",
       "2        60.0         3  11250.0       1         0            3          0   \n",
       "3        70.0         3   9550.0       1         0            3          0   \n",
       "4        60.0         3  14260.0       1         0            3          0   \n",
       "\n",
       "   LotConfig  LandSlope  Neighborhood  ...  OpenPorchSF  EnclosedPorch  \\\n",
       "0          4          0             5  ...         61.0            0.0   \n",
       "1          2          0            24  ...          0.0            0.0   \n",
       "2          4          0             5  ...         42.0            0.0   \n",
       "3          0          0             6  ...         35.0          272.0   \n",
       "4          2          0            15  ...         84.0            0.0   \n",
       "\n",
       "   3SsnPorch  ScreenPorch  PoolArea  MiscVal  MoSold  YrSold  SaleType  \\\n",
       "0        0.0          0.0       0.0      0.0     2.0  2008.0         8   \n",
       "1        0.0          0.0       0.0      0.0     5.0  2007.0         8   \n",
       "2        0.0          0.0       0.0      0.0     9.0  2008.0         8   \n",
       "3        0.0          0.0       0.0      0.0     2.0  2006.0         8   \n",
       "4        0.0          0.0       0.0      0.0    12.0  2008.0         8   \n",
       "\n",
       "   SaleCondition  \n",
       "0              4  \n",
       "1              4  \n",
       "2              4  \n",
       "3              0  \n",
       "4              4  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filling all else data using k nearest neighbours\n",
    "df_encoded = df_combined.copy()\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    df_encoded[col] = encoder.fit_transform(df_combined[col].astype(str))\n",
    "    \n",
    "imputer = KNNImputer(n_neighbors = 3)\n",
    "\n",
    "df_combined = pd.DataFrame(imputer.fit_transform(df_encoded), columns=df_encoded.columns)\n",
    "\n",
    "for col in categorical_columns:\n",
    "    df_combined[col] = df_combined[col].astype(int).astype('category').cat.categories[df_combined[col].astype(int)]\n",
    "\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoding categorical columns and normalising data from numerical columns\n",
    "df_combined = pd.get_dummies(df_combined, columns=categorical_columns)\n",
    "\n",
    "df_combined[numerical_columns] = np.log1p(df_combined[numerical_columns])\n",
    "df_combined[numerical_columns] = (df_combined[numerical_columns] - df_combined[numerical_columns].mean()) / (df_combined[numerical_columns].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_threshold = 1\n",
    "similar_columns = []\n",
    "\n",
    "similar_columns = []\n",
    "for i in range(df_combined.shape[1]):\n",
    "    for j in range(i+1, df_combined.shape[1]):\n",
    "        similarity = np.mean(df_combined.iloc[:, i] == df_combined.iloc[:, j])\n",
    "        if similarity >= similarity_threshold:\n",
    "            similar_columns.append(df_combined.columns[j])\n",
    "\n",
    "similar_columns = set(similar_columns)\n",
    "\n",
    "df_combined = df_combined.drop(similar_columns, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 273), (1459, 272))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_combined.loc[:1459]\n",
    "df_test_final = df_combined.loc[1460:]\n",
    "\n",
    "df_final_train = pd.concat([df_train, df_final_train], axis = 1)\n",
    "\n",
    "df_final_train.shape, df_test_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 272)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = df_final_train.copy()\n",
    "submission_data = df_test_final.copy()\n",
    "\n",
    "# Shuffling the data \n",
    "train_data = train_data.sample(frac = 1)\n",
    "\n",
    "# Convering values into numpy arrays\n",
    "y = (train_data['SalePrice']).values\n",
    "train_data = train_data.drop(columns='SalePrice', axis = 1)\n",
    "x = train_data.values\n",
    "\n",
    "submission = submission_data.values\n",
    "\n",
    "x = x.astype('float')\n",
    "y = y.astype('float')\n",
    "submission = submission.astype('float')\n",
    "\n",
    "y = np.log(y)\n",
    "\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 272)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                5460      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 272)               5712      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,172\n",
      "Trainable params: 11,172\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 272)]             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                5460      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,681\n",
      "Trainable params: 5,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = x.shape[1]\n",
    "\n",
    "# Creating autoencoder\n",
    "encoder_input = tf.keras.Input(shape=input_dim)\n",
    "encoder_hidden_1 = tf.keras.layers.Dense(20, activation='relu')(encoder_input)\n",
    "\n",
    "decoder_output = tf.keras.layers.Dense(input_dim, activation='sigmoid')(encoder_hidden_1)\n",
    "\n",
    "autoencoder = tf.keras.Model(encoder_input, decoder_output)\n",
    "\n",
    "# Creating neural network\n",
    "neural_network_input = tf.keras.Input(shape=input_dim)\n",
    "neural_network_hidden1 = tf.keras.layers.Dense(20, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.01))(neural_network_input)\n",
    "neural_network_hidden2 = tf.keras.layers.Dense(10, activation='relu', kernel_regularizer=tf.keras.regularizers.l1(0.01))(neural_network_hidden1)\n",
    "neural_network_output = tf.keras.layers.Dense(1)(neural_network_hidden2)\n",
    "\n",
    "model = tf.keras.Model(neural_network_input, neural_network_output)\n",
    "\n",
    "autoencoder.summary(), model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    loss = tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "# model.compile(optimizer='adam', loss=rmse, metrics=['mape'])\n",
    "\n",
    "# autoencoder.fit(x, x, epochs = 100, validation_split=0.2)\n",
    "\n",
    "# x_autoencoded = autoencoder.predict(x)\n",
    "\n",
    "# model.fit(x_autoencoded, y, epochs = 1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1250\n",
      "37/37 [==============================] - 1s 6ms/step - loss: 14.1446 - val_loss: 11.3093\n",
      "Epoch 2/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 7.5832 - val_loss: 3.1608\n",
      "Epoch 3/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2.7374 - val_loss: 2.1785\n",
      "Epoch 4/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.9655 - val_loss: 1.8004\n",
      "Epoch 5/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.6717 - val_loss: 1.6216\n",
      "Epoch 6/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.5134 - val_loss: 1.5102\n",
      "Epoch 7/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.3992 - val_loss: 1.4061\n",
      "Epoch 8/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.3023 - val_loss: 1.3212\n",
      "Epoch 9/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.2313 - val_loss: 1.2571\n",
      "Epoch 10/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.1708 - val_loss: 1.2105\n",
      "Epoch 11/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.1165 - val_loss: 1.1643\n",
      "Epoch 12/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.0722 - val_loss: 1.1251\n",
      "Epoch 13/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.0343 - val_loss: 1.1023\n",
      "Epoch 14/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1.0135 - val_loss: 1.0673\n",
      "Epoch 15/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.9671 - val_loss: 1.0164\n",
      "Epoch 16/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9356 - val_loss: 1.0146\n",
      "Epoch 17/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.9181 - val_loss: 0.9769\n",
      "Epoch 18/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.8894 - val_loss: 0.9409\n",
      "Epoch 19/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.8604 - val_loss: 0.9263\n",
      "Epoch 20/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8452 - val_loss: 0.9018\n",
      "Epoch 21/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8154 - val_loss: 0.8824\n",
      "Epoch 22/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8112 - val_loss: 0.8837\n",
      "Epoch 23/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.7782 - val_loss: 0.8387\n",
      "Epoch 24/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.7658 - val_loss: 0.8262\n",
      "Epoch 25/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.7518 - val_loss: 0.8102\n",
      "Epoch 26/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.7332 - val_loss: 0.7912\n",
      "Epoch 27/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.7258 - val_loss: 0.7956\n",
      "Epoch 28/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.7253 - val_loss: 0.7761\n",
      "Epoch 29/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.6989 - val_loss: 0.7596\n",
      "Epoch 30/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.6911 - val_loss: 0.7550\n",
      "Epoch 31/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6752 - val_loss: 0.7391\n",
      "Epoch 32/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6682 - val_loss: 0.7294\n",
      "Epoch 33/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6531 - val_loss: 0.7107\n",
      "Epoch 34/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.6413 - val_loss: 0.6910\n",
      "Epoch 35/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6289 - val_loss: 0.6888\n",
      "Epoch 36/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.6269 - val_loss: 0.6869\n",
      "Epoch 37/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6325 - val_loss: 0.6672\n",
      "Epoch 38/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.6189 - val_loss: 0.6767\n",
      "Epoch 39/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.6042 - val_loss: 0.6962\n",
      "Epoch 40/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5962 - val_loss: 0.6515\n",
      "Epoch 41/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5873 - val_loss: 0.6360\n",
      "Epoch 42/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5772 - val_loss: 0.6350\n",
      "Epoch 43/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5763 - val_loss: 0.6184\n",
      "Epoch 44/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5668 - val_loss: 0.6244\n",
      "Epoch 45/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5600 - val_loss: 0.6256\n",
      "Epoch 46/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5572 - val_loss: 0.6076\n",
      "Epoch 47/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5448 - val_loss: 0.5990\n",
      "Epoch 48/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5465 - val_loss: 0.6326\n",
      "Epoch 49/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5400 - val_loss: 0.5900\n",
      "Epoch 50/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5385 - val_loss: 0.5812\n",
      "Epoch 51/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5329 - val_loss: 0.5666\n",
      "Epoch 52/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5220 - val_loss: 0.5577\n",
      "Epoch 53/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5200 - val_loss: 0.5501\n",
      "Epoch 54/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5180 - val_loss: 0.5635\n",
      "Epoch 55/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5157 - val_loss: 0.5562\n",
      "Epoch 56/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.5061 - val_loss: 0.5646\n",
      "Epoch 57/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5067 - val_loss: 0.5377\n",
      "Epoch 58/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4970 - val_loss: 0.5442\n",
      "Epoch 59/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4938 - val_loss: 0.5378\n",
      "Epoch 60/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4880 - val_loss: 0.5233\n",
      "Epoch 61/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4877 - val_loss: 0.5209\n",
      "Epoch 62/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4783 - val_loss: 0.5196\n",
      "Epoch 63/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4754 - val_loss: 0.5186\n",
      "Epoch 64/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4792 - val_loss: 0.5060\n",
      "Epoch 65/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4701 - val_loss: 0.5034\n",
      "Epoch 66/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4643 - val_loss: 0.5264\n",
      "Epoch 67/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4679 - val_loss: 0.4913\n",
      "Epoch 68/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4631 - val_loss: 0.4971\n",
      "Epoch 69/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4638 - val_loss: 0.4926\n",
      "Epoch 70/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4782 - val_loss: 0.4895\n",
      "Epoch 71/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4592 - val_loss: 0.4764\n",
      "Epoch 72/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4484 - val_loss: 0.4805\n",
      "Epoch 73/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4415 - val_loss: 0.4811\n",
      "Epoch 74/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4475 - val_loss: 0.4734\n",
      "Epoch 75/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4409 - val_loss: 0.4828\n",
      "Epoch 76/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4490 - val_loss: 0.4836\n",
      "Epoch 77/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4425 - val_loss: 0.4816\n",
      "Epoch 78/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4332 - val_loss: 0.4802\n",
      "Epoch 79/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4339 - val_loss: 0.4652\n",
      "Epoch 80/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4303 - val_loss: 0.4606\n",
      "Epoch 81/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4227 - val_loss: 0.4503\n",
      "Epoch 82/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4208 - val_loss: 0.4869\n",
      "Epoch 83/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4322 - val_loss: 0.4748\n",
      "Epoch 84/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4268 - val_loss: 0.4527\n",
      "Epoch 85/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4264 - val_loss: 0.4508\n",
      "Epoch 86/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4154 - val_loss: 0.4511\n",
      "Epoch 87/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4165 - val_loss: 0.4661\n",
      "Epoch 88/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.4098 - val_loss: 0.4298\n",
      "Epoch 89/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4101 - val_loss: 0.4526\n",
      "Epoch 90/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4221 - val_loss: 0.4313\n",
      "Epoch 91/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4058 - val_loss: 0.4388\n",
      "Epoch 92/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4044 - val_loss: 0.4352\n",
      "Epoch 93/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4059 - val_loss: 0.4321\n",
      "Epoch 94/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4119 - val_loss: 0.4318\n",
      "Epoch 95/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4067 - val_loss: 0.4283\n",
      "Epoch 96/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4027 - val_loss: 0.4189\n",
      "Epoch 97/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3891 - val_loss: 0.4228\n",
      "Epoch 98/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3922 - val_loss: 0.4145\n",
      "Epoch 99/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3964 - val_loss: 0.4127\n",
      "Epoch 100/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3901 - val_loss: 0.4219\n",
      "Epoch 101/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3864 - val_loss: 0.4086\n",
      "Epoch 102/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3871 - val_loss: 0.4107\n",
      "Epoch 103/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.4338\n",
      "Epoch 104/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3893 - val_loss: 0.4031\n",
      "Epoch 105/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3877 - val_loss: 0.4040\n",
      "Epoch 106/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3821 - val_loss: 0.4002\n",
      "Epoch 107/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3774 - val_loss: 0.4013\n",
      "Epoch 108/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3717 - val_loss: 0.3991\n",
      "Epoch 109/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3683 - val_loss: 0.4035\n",
      "Epoch 110/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3760 - val_loss: 0.4156\n",
      "Epoch 111/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3832 - val_loss: 0.4217\n",
      "Epoch 112/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3680 - val_loss: 0.3987\n",
      "Epoch 113/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3746 - val_loss: 0.4070\n",
      "Epoch 114/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3738 - val_loss: 0.4130\n",
      "Epoch 115/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3725 - val_loss: 0.3955\n",
      "Epoch 116/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3702 - val_loss: 0.3922\n",
      "Epoch 117/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3588 - val_loss: 0.4055\n",
      "Epoch 118/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3785 - val_loss: 0.4098\n",
      "Epoch 119/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3622 - val_loss: 0.3858\n",
      "Epoch 120/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3609 - val_loss: 0.3871\n",
      "Epoch 121/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3610 - val_loss: 0.3883\n",
      "Epoch 122/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3673 - val_loss: 0.4006\n",
      "Epoch 123/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3650 - val_loss: 0.3724\n",
      "Epoch 124/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3500 - val_loss: 0.3765\n",
      "Epoch 125/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3546 - val_loss: 0.3867\n",
      "Epoch 126/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3528 - val_loss: 0.3815\n",
      "Epoch 127/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3572 - val_loss: 0.3930\n",
      "Epoch 128/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3547 - val_loss: 0.3751\n",
      "Epoch 129/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3564 - val_loss: 0.3757\n",
      "Epoch 130/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3557 - val_loss: 0.3644\n",
      "Epoch 131/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3462 - val_loss: 0.3812\n",
      "Epoch 132/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3488 - val_loss: 0.3566\n",
      "Epoch 133/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3417 - val_loss: 0.3647\n",
      "Epoch 134/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3440 - val_loss: 0.3764\n",
      "Epoch 135/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3422 - val_loss: 0.3602\n",
      "Epoch 136/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3344 - val_loss: 0.3531\n",
      "Epoch 137/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3385 - val_loss: 0.3769\n",
      "Epoch 138/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3499 - val_loss: 0.3688\n",
      "Epoch 139/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3441 - val_loss: 0.3667\n",
      "Epoch 140/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3496 - val_loss: 0.3596\n",
      "Epoch 141/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3429 - val_loss: 0.3674\n",
      "Epoch 142/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3495 - val_loss: 0.3758\n",
      "Epoch 143/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3377 - val_loss: 0.3509\n",
      "Epoch 144/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3285 - val_loss: 0.3709\n",
      "Epoch 145/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3372 - val_loss: 0.3406\n",
      "Epoch 146/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3242 - val_loss: 0.3474\n",
      "Epoch 147/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3303 - val_loss: 0.3488\n",
      "Epoch 148/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3295 - val_loss: 0.3492\n",
      "Epoch 149/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3276 - val_loss: 0.3561\n",
      "Epoch 150/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3292 - val_loss: 0.3594\n",
      "Epoch 151/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3292 - val_loss: 0.3510\n",
      "Epoch 152/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3238 - val_loss: 0.3454\n",
      "Epoch 153/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3233 - val_loss: 0.3448\n",
      "Epoch 154/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3235 - val_loss: 0.3605\n",
      "Epoch 155/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3320 - val_loss: 0.3553\n",
      "Epoch 156/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3271 - val_loss: 0.3509\n",
      "Epoch 157/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3236 - val_loss: 0.3332\n",
      "Epoch 158/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3276 - val_loss: 0.3365\n",
      "Epoch 159/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3233 - val_loss: 0.3802\n",
      "Epoch 160/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3320 - val_loss: 0.3395\n",
      "Epoch 161/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3253 - val_loss: 0.3249\n",
      "Epoch 162/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3180 - val_loss: 0.3527\n",
      "Epoch 163/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3235 - val_loss: 0.3520\n",
      "Epoch 164/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3238 - val_loss: 0.3291\n",
      "Epoch 165/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3146 - val_loss: 0.3352\n",
      "Epoch 166/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3277 - val_loss: 0.3537\n",
      "Epoch 167/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3233 - val_loss: 0.3295\n",
      "Epoch 168/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3154 - val_loss: 0.3316\n",
      "Epoch 169/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3128 - val_loss: 0.3230\n",
      "Epoch 170/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3086 - val_loss: 0.3250\n",
      "Epoch 171/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3139 - val_loss: 0.3151\n",
      "Epoch 172/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3138 - val_loss: 0.3285\n",
      "Epoch 173/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3095 - val_loss: 0.3369\n",
      "Epoch 174/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3127 - val_loss: 0.3581\n",
      "Epoch 175/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3215 - val_loss: 0.3209\n",
      "Epoch 176/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3081 - val_loss: 0.3271\n",
      "Epoch 177/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3122 - val_loss: 0.3240\n",
      "Epoch 178/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3093 - val_loss: 0.3169\n",
      "Epoch 179/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3108 - val_loss: 0.3316\n",
      "Epoch 180/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3061 - val_loss: 0.3206\n",
      "Epoch 181/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3074 - val_loss: 0.3225\n",
      "Epoch 182/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3186 - val_loss: 0.3324\n",
      "Epoch 183/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3072 - val_loss: 0.3231\n",
      "Epoch 184/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3104 - val_loss: 0.3123\n",
      "Epoch 185/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.3050 - val_loss: 0.3141\n",
      "Epoch 186/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3008 - val_loss: 0.3145\n",
      "Epoch 187/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2988 - val_loss: 0.3202\n",
      "Epoch 188/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3066 - val_loss: 0.3235\n",
      "Epoch 189/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3023 - val_loss: 0.3164\n",
      "Epoch 190/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2975 - val_loss: 0.3152\n",
      "Epoch 191/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3014 - val_loss: 0.3157\n",
      "Epoch 192/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2979 - val_loss: 0.3235\n",
      "Epoch 193/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3210 - val_loss: 0.3079\n",
      "Epoch 194/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3053 - val_loss: 0.3127\n",
      "Epoch 195/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3011 - val_loss: 0.3088\n",
      "Epoch 196/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2958 - val_loss: 0.3225\n",
      "Epoch 197/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2977 - val_loss: 0.3205\n",
      "Epoch 198/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2997 - val_loss: 0.3146\n",
      "Epoch 199/1250\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3040 - val_loss: 0.3173\n",
      "Epoch 200/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2959 - val_loss: 0.3038\n",
      "Epoch 201/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2886 - val_loss: 0.3190\n",
      "Epoch 202/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2951 - val_loss: 0.3049\n",
      "Epoch 203/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2886 - val_loss: 0.2964\n",
      "Epoch 204/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2911 - val_loss: 0.2989\n",
      "Epoch 205/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2940 - val_loss: 0.3356\n",
      "Epoch 206/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2932 - val_loss: 0.3131\n",
      "Epoch 207/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2878 - val_loss: 0.2953\n",
      "Epoch 208/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2922 - val_loss: 0.3008\n",
      "Epoch 209/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2835 - val_loss: 0.3019\n",
      "Epoch 210/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2874 - val_loss: 0.3050\n",
      "Epoch 211/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2871 - val_loss: 0.3044\n",
      "Epoch 212/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2985 - val_loss: 0.2970\n",
      "Epoch 213/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2866 - val_loss: 0.2993\n",
      "Epoch 214/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2891 - val_loss: 0.3032\n",
      "Epoch 215/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2916 - val_loss: 0.3104\n",
      "Epoch 216/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2906 - val_loss: 0.2984\n",
      "Epoch 217/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2833 - val_loss: 0.3019\n",
      "Epoch 218/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2856 - val_loss: 0.3042\n",
      "Epoch 219/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2866 - val_loss: 0.3017\n",
      "Epoch 220/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2852 - val_loss: 0.3007\n",
      "Epoch 221/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2874 - val_loss: 0.2991\n",
      "Epoch 222/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2862 - val_loss: 0.3009\n",
      "Epoch 223/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2823 - val_loss: 0.3089\n",
      "Epoch 224/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2798 - val_loss: 0.2830\n",
      "Epoch 225/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2840 - val_loss: 0.3102\n",
      "Epoch 226/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2835 - val_loss: 0.2941\n",
      "Epoch 227/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2793 - val_loss: 0.2909\n",
      "Epoch 228/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2822 - val_loss: 0.2914\n",
      "Epoch 229/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2816 - val_loss: 0.3087\n",
      "Epoch 230/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2777 - val_loss: 0.2864\n",
      "Epoch 231/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2825 - val_loss: 0.3121\n",
      "Epoch 232/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2840 - val_loss: 0.2904\n",
      "Epoch 233/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2724 - val_loss: 0.3023\n",
      "Epoch 234/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2855 - val_loss: 0.3338\n",
      "Epoch 235/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2838 - val_loss: 0.2920\n",
      "Epoch 236/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2821 - val_loss: 0.3086\n",
      "Epoch 237/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2773 - val_loss: 0.2938\n",
      "Epoch 238/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2794 - val_loss: 0.2864\n",
      "Epoch 239/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2770 - val_loss: 0.2878\n",
      "Epoch 240/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2899 - val_loss: 0.2829\n",
      "Epoch 241/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2764 - val_loss: 0.3068\n",
      "Epoch 242/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2697 - val_loss: 0.2836\n",
      "Epoch 243/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2677 - val_loss: 0.2907\n",
      "Epoch 244/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2803 - val_loss: 0.2818\n",
      "Epoch 245/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2756 - val_loss: 0.2974\n",
      "Epoch 246/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2749 - val_loss: 0.2830\n",
      "Epoch 247/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2735 - val_loss: 0.2836\n",
      "Epoch 248/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2738 - val_loss: 0.2810\n",
      "Epoch 249/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2776 - val_loss: 0.2985\n",
      "Epoch 250/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2818 - val_loss: 0.2966\n",
      "Epoch 251/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2663 - val_loss: 0.2898\n",
      "Epoch 252/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2690 - val_loss: 0.2903\n",
      "Epoch 253/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2700 - val_loss: 0.3008\n",
      "Epoch 254/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2753 - val_loss: 0.2789\n",
      "Epoch 255/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2710 - val_loss: 0.2902\n",
      "Epoch 256/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2706 - val_loss: 0.2770\n",
      "Epoch 257/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2663 - val_loss: 0.2788\n",
      "Epoch 258/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2637 - val_loss: 0.3002\n",
      "Epoch 259/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2674 - val_loss: 0.2762\n",
      "Epoch 260/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2802 - val_loss: 0.3112\n",
      "Epoch 261/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2737 - val_loss: 0.2994\n",
      "Epoch 262/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2667 - val_loss: 0.2756\n",
      "Epoch 263/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2716 - val_loss: 0.2875\n",
      "Epoch 264/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2682 - val_loss: 0.2820\n",
      "Epoch 265/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2642 - val_loss: 0.2704\n",
      "Epoch 266/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2711 - val_loss: 0.2727\n",
      "Epoch 267/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2644 - val_loss: 0.2849\n",
      "Epoch 268/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2702 - val_loss: 0.2809\n",
      "Epoch 269/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2673 - val_loss: 0.2781\n",
      "Epoch 270/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2781 - val_loss: 0.2760\n",
      "Epoch 271/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2741 - val_loss: 0.2842\n",
      "Epoch 272/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2595 - val_loss: 0.2761\n",
      "Epoch 273/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2598 - val_loss: 0.2680\n",
      "Epoch 274/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2569 - val_loss: 0.2704\n",
      "Epoch 275/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2613 - val_loss: 0.2711\n",
      "Epoch 276/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2673 - val_loss: 0.2961\n",
      "Epoch 277/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2705 - val_loss: 0.2877\n",
      "Epoch 278/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2729 - val_loss: 0.2825\n",
      "Epoch 279/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2636 - val_loss: 0.3010\n",
      "Epoch 280/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2686 - val_loss: 0.2738\n",
      "Epoch 281/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2581 - val_loss: 0.2720\n",
      "Epoch 282/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2603 - val_loss: 0.2629\n",
      "Epoch 283/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2597 - val_loss: 0.2686\n",
      "Epoch 284/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2559 - val_loss: 0.2675\n",
      "Epoch 285/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2638 - val_loss: 0.2755\n",
      "Epoch 286/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2604 - val_loss: 0.2711\n",
      "Epoch 287/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2565 - val_loss: 0.2720\n",
      "Epoch 288/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2558 - val_loss: 0.2703\n",
      "Epoch 289/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2532 - val_loss: 0.2751\n",
      "Epoch 290/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2556 - val_loss: 0.2686\n",
      "Epoch 291/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2554 - val_loss: 0.2790\n",
      "Epoch 292/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2579 - val_loss: 0.2690\n",
      "Epoch 293/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2542 - val_loss: 0.2607\n",
      "Epoch 294/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2512 - val_loss: 0.2946\n",
      "Epoch 295/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2666 - val_loss: 0.2677\n",
      "Epoch 296/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2584 - val_loss: 0.2985\n",
      "Epoch 297/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2563 - val_loss: 0.2598\n",
      "Epoch 298/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2584 - val_loss: 0.2721\n",
      "Epoch 299/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2537 - val_loss: 0.2602\n",
      "Epoch 300/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2541 - val_loss: 0.2809\n",
      "Epoch 301/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2546 - val_loss: 0.2581\n",
      "Epoch 302/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2532 - val_loss: 0.2660\n",
      "Epoch 303/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2476 - val_loss: 0.2630\n",
      "Epoch 304/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2572 - val_loss: 0.2710\n",
      "Epoch 305/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2493 - val_loss: 0.2546\n",
      "Epoch 306/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2544 - val_loss: 0.3051\n",
      "Epoch 307/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2578 - val_loss: 0.2748\n",
      "Epoch 308/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2605 - val_loss: 0.2841\n",
      "Epoch 309/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2654 - val_loss: 0.2630\n",
      "Epoch 310/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2469 - val_loss: 0.2661\n",
      "Epoch 311/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2444 - val_loss: 0.2593\n",
      "Epoch 312/1250\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2505 - val_loss: 0.2596\n",
      "Epoch 313/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2459 - val_loss: 0.2657\n",
      "Epoch 314/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2515 - val_loss: 0.2541\n",
      "Epoch 315/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2491 - val_loss: 0.2625\n",
      "Epoch 316/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2604 - val_loss: 0.2688\n",
      "Epoch 317/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2501 - val_loss: 0.2574\n",
      "Epoch 318/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2576 - val_loss: 0.2557\n",
      "Epoch 319/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2458 - val_loss: 0.2625\n",
      "Epoch 320/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2463 - val_loss: 0.2495\n",
      "Epoch 321/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2445 - val_loss: 0.2640\n",
      "Epoch 322/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2422 - val_loss: 0.2676\n",
      "Epoch 323/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2508 - val_loss: 0.2508\n",
      "Epoch 324/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2452 - val_loss: 0.2590\n",
      "Epoch 325/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2497 - val_loss: 0.2757\n",
      "Epoch 326/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2532 - val_loss: 0.2547\n",
      "Epoch 327/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2473 - val_loss: 0.2595\n",
      "Epoch 328/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2438 - val_loss: 0.2447\n",
      "Epoch 329/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2426 - val_loss: 0.2624\n",
      "Epoch 330/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2478 - val_loss: 0.2519\n",
      "Epoch 331/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2398 - val_loss: 0.2570\n",
      "Epoch 332/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2511 - val_loss: 0.2554\n",
      "Epoch 333/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2388 - val_loss: 0.2555\n",
      "Epoch 334/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2433 - val_loss: 0.2756\n",
      "Epoch 335/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2563 - val_loss: 0.2475\n",
      "Epoch 336/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2411 - val_loss: 0.2524\n",
      "Epoch 337/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2427 - val_loss: 0.2584\n",
      "Epoch 338/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2457 - val_loss: 0.2631\n",
      "Epoch 339/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2439 - val_loss: 0.3000\n",
      "Epoch 340/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2406 - val_loss: 0.2527\n",
      "Epoch 341/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2461 - val_loss: 0.2715\n",
      "Epoch 342/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2460 - val_loss: 0.2487\n",
      "Epoch 343/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2413 - val_loss: 0.2481\n",
      "Epoch 344/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2433 - val_loss: 0.2547\n",
      "Epoch 345/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2392 - val_loss: 0.2426\n",
      "Epoch 346/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2361 - val_loss: 0.2563\n",
      "Epoch 347/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2427 - val_loss: 0.2477\n",
      "Epoch 348/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2432 - val_loss: 0.2536\n",
      "Epoch 349/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2412 - val_loss: 0.2399\n",
      "Epoch 350/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2360 - val_loss: 0.2524\n",
      "Epoch 351/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2378 - val_loss: 0.2648\n",
      "Epoch 352/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2413 - val_loss: 0.2408\n",
      "Epoch 353/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2330 - val_loss: 0.2450\n",
      "Epoch 354/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2345 - val_loss: 0.2596\n",
      "Epoch 355/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2375 - val_loss: 0.2490\n",
      "Epoch 356/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2441 - val_loss: 0.2479\n",
      "Epoch 357/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2361 - val_loss: 0.2548\n",
      "Epoch 358/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2337 - val_loss: 0.2589\n",
      "Epoch 359/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2400 - val_loss: 0.2428\n",
      "Epoch 360/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2347 - val_loss: 0.2397\n",
      "Epoch 361/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2294 - val_loss: 0.2435\n",
      "Epoch 362/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2391 - val_loss: 0.2694\n",
      "Epoch 363/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2360 - val_loss: 0.2444\n",
      "Epoch 364/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2339 - val_loss: 0.2397\n",
      "Epoch 365/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2335 - val_loss: 0.2470\n",
      "Epoch 366/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2277 - val_loss: 0.2387\n",
      "Epoch 367/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2309 - val_loss: 0.2417\n",
      "Epoch 368/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2287 - val_loss: 0.2420\n",
      "Epoch 369/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2286 - val_loss: 0.2530\n",
      "Epoch 370/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2405 - val_loss: 0.2625\n",
      "Epoch 371/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2411 - val_loss: 0.2518\n",
      "Epoch 372/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2291 - val_loss: 0.2405\n",
      "Epoch 373/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2251 - val_loss: 0.2390\n",
      "Epoch 374/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2311 - val_loss: 0.2387\n",
      "Epoch 375/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2336 - val_loss: 0.2437\n",
      "Epoch 376/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2312 - val_loss: 0.2404\n",
      "Epoch 377/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2342 - val_loss: 0.2586\n",
      "Epoch 378/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2412 - val_loss: 0.2516\n",
      "Epoch 379/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2263 - val_loss: 0.2362\n",
      "Epoch 380/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2243 - val_loss: 0.2514\n",
      "Epoch 381/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2297 - val_loss: 0.2521\n",
      "Epoch 382/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2302 - val_loss: 0.2300\n",
      "Epoch 383/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2322 - val_loss: 0.2346\n",
      "Epoch 384/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2390 - val_loss: 0.2271\n",
      "Epoch 385/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2361 - val_loss: 0.2373\n",
      "Epoch 386/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2314 - val_loss: 0.2323\n",
      "Epoch 387/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2266 - val_loss: 0.2602\n",
      "Epoch 388/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2256 - val_loss: 0.2355\n",
      "Epoch 389/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2283 - val_loss: 0.2341\n",
      "Epoch 390/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2218 - val_loss: 0.2369\n",
      "Epoch 391/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2236 - val_loss: 0.2484\n",
      "Epoch 392/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2281 - val_loss: 0.2320\n",
      "Epoch 393/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2213 - val_loss: 0.2295\n",
      "Epoch 394/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2214 - val_loss: 0.2419\n",
      "Epoch 395/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2249 - val_loss: 0.2421\n",
      "Epoch 396/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2297 - val_loss: 0.2341\n",
      "Epoch 397/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2246 - val_loss: 0.2401\n",
      "Epoch 398/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2252 - val_loss: 0.2269\n",
      "Epoch 399/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2254 - val_loss: 0.2383\n",
      "Epoch 400/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2274 - val_loss: 0.2339\n",
      "Epoch 401/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2191 - val_loss: 0.2311\n",
      "Epoch 402/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2171 - val_loss: 0.2347\n",
      "Epoch 403/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2210 - val_loss: 0.2520\n",
      "Epoch 404/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2313 - val_loss: 0.2296\n",
      "Epoch 405/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2230 - val_loss: 0.2314\n",
      "Epoch 406/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2258 - val_loss: 0.2331\n",
      "Epoch 407/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2221 - val_loss: 0.2258\n",
      "Epoch 408/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2277 - val_loss: 0.2464\n",
      "Epoch 409/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2265 - val_loss: 0.2256\n",
      "Epoch 410/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2193 - val_loss: 0.2291\n",
      "Epoch 411/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2189 - val_loss: 0.2305\n",
      "Epoch 412/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2241 - val_loss: 0.2320\n",
      "Epoch 413/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2204 - val_loss: 0.2459\n",
      "Epoch 414/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2226 - val_loss: 0.2239\n",
      "Epoch 415/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2221 - val_loss: 0.2319\n",
      "Epoch 416/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2177 - val_loss: 0.2229\n",
      "Epoch 417/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2131 - val_loss: 0.2223\n",
      "Epoch 418/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2173 - val_loss: 0.2299\n",
      "Epoch 419/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2223 - val_loss: 0.2316\n",
      "Epoch 420/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2176 - val_loss: 0.2232\n",
      "Epoch 421/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2162 - val_loss: 0.2310\n",
      "Epoch 422/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2203 - val_loss: 0.2231\n",
      "Epoch 423/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2235 - val_loss: 0.2245\n",
      "Epoch 424/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2155 - val_loss: 0.2302\n",
      "Epoch 425/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2295 - val_loss: 0.2276\n",
      "Epoch 426/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2239 - val_loss: 0.2221\n",
      "Epoch 427/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2181 - val_loss: 0.2431\n",
      "Epoch 428/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2198 - val_loss: 0.2308\n",
      "Epoch 429/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2120 - val_loss: 0.2265\n",
      "Epoch 430/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2246 - val_loss: 0.2278\n",
      "Epoch 431/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2166 - val_loss: 0.2294\n",
      "Epoch 432/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2126 - val_loss: 0.2282\n",
      "Epoch 433/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2147 - val_loss: 0.2318\n",
      "Epoch 434/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2148 - val_loss: 0.2155\n",
      "Epoch 435/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2131 - val_loss: 0.2231\n",
      "Epoch 436/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2157 - val_loss: 0.2254\n",
      "Epoch 437/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2144 - val_loss: 0.2271\n",
      "Epoch 438/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2187 - val_loss: 0.2592\n",
      "Epoch 439/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2218 - val_loss: 0.2226\n",
      "Epoch 440/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2141 - val_loss: 0.2205\n",
      "Epoch 441/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2108 - val_loss: 0.2255\n",
      "Epoch 442/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2152 - val_loss: 0.2263\n",
      "Epoch 443/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2126 - val_loss: 0.2344\n",
      "Epoch 444/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2136 - val_loss: 0.2141\n",
      "Epoch 445/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2134 - val_loss: 0.2147\n",
      "Epoch 446/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2074 - val_loss: 0.2224\n",
      "Epoch 447/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2111 - val_loss: 0.2250\n",
      "Epoch 448/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2109 - val_loss: 0.2244\n",
      "Epoch 449/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2171 - val_loss: 0.2295\n",
      "Epoch 450/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2116 - val_loss: 0.2176\n",
      "Epoch 451/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2094 - val_loss: 0.2151\n",
      "Epoch 452/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2102 - val_loss: 0.2212\n",
      "Epoch 453/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2168 - val_loss: 0.2240\n",
      "Epoch 454/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2113 - val_loss: 0.2186\n",
      "Epoch 455/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2127 - val_loss: 0.2234\n",
      "Epoch 456/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2111 - val_loss: 0.2307\n",
      "Epoch 457/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2106 - val_loss: 0.2264\n",
      "Epoch 458/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2067 - val_loss: 0.2247\n",
      "Epoch 459/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2119 - val_loss: 0.2225\n",
      "Epoch 460/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2109 - val_loss: 0.2208\n",
      "Epoch 461/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2167 - val_loss: 0.2128\n",
      "Epoch 462/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2140 - val_loss: 0.2427\n",
      "Epoch 463/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2140 - val_loss: 0.2281\n",
      "Epoch 464/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2160 - val_loss: 0.2571\n",
      "Epoch 465/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2088 - val_loss: 0.2482\n",
      "Epoch 466/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2127 - val_loss: 0.2307\n",
      "Epoch 467/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2102 - val_loss: 0.2185\n",
      "Epoch 468/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2069 - val_loss: 0.2257\n",
      "Epoch 469/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2064 - val_loss: 0.2114\n",
      "Epoch 470/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2053 - val_loss: 0.2140\n",
      "Epoch 471/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2024 - val_loss: 0.2187\n",
      "Epoch 472/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2066 - val_loss: 0.2227\n",
      "Epoch 473/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2060 - val_loss: 0.2359\n",
      "Epoch 474/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2058 - val_loss: 0.2131\n",
      "Epoch 475/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2019 - val_loss: 0.2208\n",
      "Epoch 476/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2031 - val_loss: 0.2174\n",
      "Epoch 477/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2087 - val_loss: 0.2149\n",
      "Epoch 478/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2013 - val_loss: 0.2129\n",
      "Epoch 479/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2053 - val_loss: 0.2205\n",
      "Epoch 480/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2018 - val_loss: 0.2221\n",
      "Epoch 481/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2057 - val_loss: 0.2120\n",
      "Epoch 482/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2063 - val_loss: 0.2139\n",
      "Epoch 483/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2065 - val_loss: 0.2122\n",
      "Epoch 484/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2073 - val_loss: 0.2330\n",
      "Epoch 485/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2120 - val_loss: 0.2269\n",
      "Epoch 486/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2080 - val_loss: 0.2204\n",
      "Epoch 487/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2105 - val_loss: 0.2180\n",
      "Epoch 488/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.2032 - val_loss: 0.2117\n",
      "Epoch 489/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1996 - val_loss: 0.2420\n",
      "Epoch 490/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2047 - val_loss: 0.2087\n",
      "Epoch 491/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2141 - val_loss: 0.2096\n",
      "Epoch 492/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1986 - val_loss: 0.2082\n",
      "Epoch 493/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1991 - val_loss: 0.2128\n",
      "Epoch 494/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2042 - val_loss: 0.2187\n",
      "Epoch 495/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2071 - val_loss: 0.2142\n",
      "Epoch 496/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2018 - val_loss: 0.2110\n",
      "Epoch 497/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1995 - val_loss: 0.2061\n",
      "Epoch 498/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1991 - val_loss: 0.2071\n",
      "Epoch 499/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1986 - val_loss: 0.2153\n",
      "Epoch 500/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2004 - val_loss: 0.2108\n",
      "Epoch 501/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1983 - val_loss: 0.2154\n",
      "Epoch 502/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2021 - val_loss: 0.2147\n",
      "Epoch 503/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2009 - val_loss: 0.2322\n",
      "Epoch 504/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2025 - val_loss: 0.2156\n",
      "Epoch 505/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2050 - val_loss: 0.2106\n",
      "Epoch 506/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2033 - val_loss: 0.2061\n",
      "Epoch 507/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1994 - val_loss: 0.2165\n",
      "Epoch 508/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1961 - val_loss: 0.2085\n",
      "Epoch 509/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1998 - val_loss: 0.2066\n",
      "Epoch 510/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1958 - val_loss: 0.1993\n",
      "Epoch 511/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1973 - val_loss: 0.2090\n",
      "Epoch 512/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1989 - val_loss: 0.2142\n",
      "Epoch 513/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2002 - val_loss: 0.2062\n",
      "Epoch 514/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1921 - val_loss: 0.2072\n",
      "Epoch 515/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1991 - val_loss: 0.2244\n",
      "Epoch 516/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2067 - val_loss: 0.2098\n",
      "Epoch 517/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2005 - val_loss: 0.2132\n",
      "Epoch 518/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1949 - val_loss: 0.2083\n",
      "Epoch 519/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.2067\n",
      "Epoch 520/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1963 - val_loss: 0.2175\n",
      "Epoch 521/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2027 - val_loss: 0.2001\n",
      "Epoch 522/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1938 - val_loss: 0.2103\n",
      "Epoch 523/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1942 - val_loss: 0.2079\n",
      "Epoch 524/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1962 - val_loss: 0.2021\n",
      "Epoch 525/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1945 - val_loss: 0.2169\n",
      "Epoch 526/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1968 - val_loss: 0.2035\n",
      "Epoch 527/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1976 - val_loss: 0.2083\n",
      "Epoch 528/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1961 - val_loss: 0.2090\n",
      "Epoch 529/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1953 - val_loss: 0.2087\n",
      "Epoch 530/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1950 - val_loss: 0.2016\n",
      "Epoch 531/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1933 - val_loss: 0.2060\n",
      "Epoch 532/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1950 - val_loss: 0.2084\n",
      "Epoch 533/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1939 - val_loss: 0.2093\n",
      "Epoch 534/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1913 - val_loss: 0.2064\n",
      "Epoch 535/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1932 - val_loss: 0.2022\n",
      "Epoch 536/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1926 - val_loss: 0.2247\n",
      "Epoch 537/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1963 - val_loss: 0.2406\n",
      "Epoch 538/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1969 - val_loss: 0.2112\n",
      "Epoch 539/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.2064\n",
      "Epoch 540/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1943 - val_loss: 0.2060\n",
      "Epoch 541/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1960 - val_loss: 0.2196\n",
      "Epoch 542/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2001 - val_loss: 0.2068\n",
      "Epoch 543/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1939 - val_loss: 0.2040\n",
      "Epoch 544/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1936 - val_loss: 0.2116\n",
      "Epoch 545/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1925 - val_loss: 0.1986\n",
      "Epoch 546/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1945 - val_loss: 0.2008\n",
      "Epoch 547/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1927 - val_loss: 0.2016\n",
      "Epoch 548/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1962 - val_loss: 0.2067\n",
      "Epoch 549/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1963 - val_loss: 0.2097\n",
      "Epoch 550/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1898 - val_loss: 0.2087\n",
      "Epoch 551/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1891 - val_loss: 0.2068\n",
      "Epoch 552/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1951 - val_loss: 0.2098\n",
      "Epoch 553/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1905 - val_loss: 0.1938\n",
      "Epoch 554/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1880 - val_loss: 0.2020\n",
      "Epoch 555/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1888 - val_loss: 0.2065\n",
      "Epoch 556/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1903 - val_loss: 0.1989\n",
      "Epoch 557/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1901 - val_loss: 0.2016\n",
      "Epoch 558/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1890 - val_loss: 0.2126\n",
      "Epoch 559/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1931 - val_loss: 0.1997\n",
      "Epoch 560/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1912 - val_loss: 0.2154\n",
      "Epoch 561/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1966 - val_loss: 0.2056\n",
      "Epoch 562/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1967 - val_loss: 0.2052\n",
      "Epoch 563/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1871 - val_loss: 0.2098\n",
      "Epoch 564/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1937 - val_loss: 0.2375\n",
      "Epoch 565/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1975 - val_loss: 0.2069\n",
      "Epoch 566/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1908 - val_loss: 0.2015\n",
      "Epoch 567/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1920 - val_loss: 0.2059\n",
      "Epoch 568/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1904 - val_loss: 0.1963\n",
      "Epoch 569/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1854 - val_loss: 0.2013\n",
      "Epoch 570/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1924 - val_loss: 0.1966\n",
      "Epoch 571/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1870 - val_loss: 0.2161\n",
      "Epoch 572/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1969 - val_loss: 0.2186\n",
      "Epoch 573/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2026 - val_loss: 0.2144\n",
      "Epoch 574/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1879 - val_loss: 0.2100\n",
      "Epoch 575/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1923 - val_loss: 0.2261\n",
      "Epoch 576/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1875 - val_loss: 0.1978\n",
      "Epoch 577/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1955 - val_loss: 0.1940\n",
      "Epoch 578/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1919 - val_loss: 0.2011\n",
      "Epoch 579/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1877 - val_loss: 0.2098\n",
      "Epoch 580/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1893 - val_loss: 0.1976\n",
      "Epoch 581/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1855 - val_loss: 0.1990\n",
      "Epoch 582/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1873 - val_loss: 0.2114\n",
      "Epoch 583/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1878 - val_loss: 0.1939\n",
      "Epoch 584/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1891 - val_loss: 0.1970\n",
      "Epoch 585/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1836 - val_loss: 0.1910\n",
      "Epoch 586/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1841 - val_loss: 0.2040\n",
      "Epoch 587/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1941 - val_loss: 0.1972\n",
      "Epoch 588/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1881 - val_loss: 0.2008\n",
      "Epoch 589/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1858 - val_loss: 0.1942\n",
      "Epoch 590/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1846 - val_loss: 0.1981\n",
      "Epoch 591/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1841 - val_loss: 0.1987\n",
      "Epoch 592/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1882 - val_loss: 0.2078\n",
      "Epoch 593/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1915 - val_loss: 0.2010\n",
      "Epoch 594/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1851 - val_loss: 0.1966\n",
      "Epoch 595/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1861 - val_loss: 0.1953\n",
      "Epoch 596/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1866 - val_loss: 0.2211\n",
      "Epoch 597/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1909 - val_loss: 0.1957\n",
      "Epoch 598/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1817 - val_loss: 0.1919\n",
      "Epoch 599/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1830 - val_loss: 0.1903\n",
      "Epoch 600/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1862 - val_loss: 0.1960\n",
      "Epoch 601/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1820 - val_loss: 0.2095\n",
      "Epoch 602/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1859 - val_loss: 0.1922\n",
      "Epoch 603/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1892 - val_loss: 0.1997\n",
      "Epoch 604/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1845 - val_loss: 0.1940\n",
      "Epoch 605/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1834 - val_loss: 0.2095\n",
      "Epoch 606/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1828 - val_loss: 0.1952\n",
      "Epoch 607/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1821 - val_loss: 0.2060\n",
      "Epoch 608/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1870 - val_loss: 0.2087\n",
      "Epoch 609/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1872 - val_loss: 0.1935\n",
      "Epoch 610/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1836 - val_loss: 0.1945\n",
      "Epoch 611/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1821 - val_loss: 0.1994\n",
      "Epoch 612/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1862 - val_loss: 0.1918\n",
      "Epoch 613/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1834 - val_loss: 0.1956\n",
      "Epoch 614/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1820 - val_loss: 0.1929\n",
      "Epoch 615/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1797 - val_loss: 0.1961\n",
      "Epoch 616/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1796 - val_loss: 0.1860\n",
      "Epoch 617/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1803 - val_loss: 0.1902\n",
      "Epoch 618/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1853 - val_loss: 0.1864\n",
      "Epoch 619/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1901 - val_loss: 0.2009\n",
      "Epoch 620/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1881 - val_loss: 0.1938\n",
      "Epoch 621/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1831 - val_loss: 0.1999\n",
      "Epoch 622/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1885 - val_loss: 0.2119\n",
      "Epoch 623/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1819 - val_loss: 0.1990\n",
      "Epoch 624/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1788 - val_loss: 0.1907\n",
      "Epoch 625/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1814 - val_loss: 0.1870\n",
      "Epoch 626/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1774 - val_loss: 0.1967\n",
      "Epoch 627/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1814 - val_loss: 0.1933\n",
      "Epoch 628/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1785 - val_loss: 0.1886\n",
      "Epoch 629/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1797 - val_loss: 0.1915\n",
      "Epoch 630/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1821 - val_loss: 0.1901\n",
      "Epoch 631/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1813 - val_loss: 0.1881\n",
      "Epoch 632/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1780 - val_loss: 0.1879\n",
      "Epoch 633/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1769 - val_loss: 0.1949\n",
      "Epoch 634/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1838 - val_loss: 0.1885\n",
      "Epoch 635/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1822 - val_loss: 0.2015\n",
      "Epoch 636/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1788 - val_loss: 0.1873\n",
      "Epoch 637/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1808 - val_loss: 0.1934\n",
      "Epoch 638/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1811 - val_loss: 0.1929\n",
      "Epoch 639/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1885 - val_loss: 0.1870\n",
      "Epoch 640/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1782 - val_loss: 0.1934\n",
      "Epoch 641/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1816 - val_loss: 0.1831\n",
      "Epoch 642/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1781 - val_loss: 0.1888\n",
      "Epoch 643/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1853 - val_loss: 0.1995\n",
      "Epoch 644/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1794 - val_loss: 0.1861\n",
      "Epoch 645/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1774 - val_loss: 0.2045\n",
      "Epoch 646/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1808 - val_loss: 0.1867\n",
      "Epoch 647/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1781 - val_loss: 0.1868\n",
      "Epoch 648/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1765 - val_loss: 0.1803\n",
      "Epoch 649/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1757 - val_loss: 0.1929\n",
      "Epoch 650/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1761 - val_loss: 0.1953\n",
      "Epoch 651/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1807 - val_loss: 0.1972\n",
      "Epoch 652/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1756 - val_loss: 0.1854\n",
      "Epoch 653/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1772 - val_loss: 0.1919\n",
      "Epoch 654/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1820 - val_loss: 0.1890\n",
      "Epoch 655/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1764 - val_loss: 0.1947\n",
      "Epoch 656/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1831 - val_loss: 0.1867\n",
      "Epoch 657/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1774 - val_loss: 0.1990\n",
      "Epoch 658/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1768 - val_loss: 0.1857\n",
      "Epoch 659/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1769 - val_loss: 0.1831\n",
      "Epoch 660/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1784 - val_loss: 0.1882\n",
      "Epoch 661/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1777 - val_loss: 0.1868\n",
      "Epoch 662/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1766 - val_loss: 0.1872\n",
      "Epoch 663/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1762 - val_loss: 0.2047\n",
      "Epoch 664/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1830 - val_loss: 0.1823\n",
      "Epoch 665/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1764 - val_loss: 0.1842\n",
      "Epoch 666/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1747 - val_loss: 0.1947\n",
      "Epoch 667/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1797 - val_loss: 0.1855\n",
      "Epoch 668/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1779 - val_loss: 0.1902\n",
      "Epoch 669/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1804 - val_loss: 0.1831\n",
      "Epoch 670/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1731 - val_loss: 0.1919\n",
      "Epoch 671/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1726 - val_loss: 0.1839\n",
      "Epoch 672/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1737 - val_loss: 0.1838\n",
      "Epoch 673/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1738 - val_loss: 0.1873\n",
      "Epoch 674/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1742 - val_loss: 0.1893\n",
      "Epoch 675/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1753 - val_loss: 0.1868\n",
      "Epoch 676/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1731 - val_loss: 0.1981\n",
      "Epoch 677/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1814 - val_loss: 0.1862\n",
      "Epoch 678/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1744 - val_loss: 0.1854\n",
      "Epoch 679/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1772 - val_loss: 0.1847\n",
      "Epoch 680/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1756 - val_loss: 0.1956\n",
      "Epoch 681/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1806 - val_loss: 0.1940\n",
      "Epoch 682/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1789 - val_loss: 0.1852\n",
      "Epoch 683/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1833 - val_loss: 0.1948\n",
      "Epoch 684/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1767 - val_loss: 0.1873\n",
      "Epoch 685/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1735 - val_loss: 0.1900\n",
      "Epoch 686/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1774 - val_loss: 0.1895\n",
      "Epoch 687/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1756 - val_loss: 0.1824\n",
      "Epoch 688/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1710 - val_loss: 0.1862\n",
      "Epoch 689/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1741 - val_loss: 0.1883\n",
      "Epoch 690/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1780 - val_loss: 0.1970\n",
      "Epoch 691/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1762 - val_loss: 0.1940\n",
      "Epoch 692/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1722 - val_loss: 0.1851\n",
      "Epoch 693/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1735 - val_loss: 0.1757\n",
      "Epoch 694/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1739 - val_loss: 0.1892\n",
      "Epoch 695/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1745 - val_loss: 0.1920\n",
      "Epoch 696/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1708 - val_loss: 0.1806\n",
      "Epoch 697/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1709 - val_loss: 0.1940\n",
      "Epoch 698/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1716 - val_loss: 0.1798\n",
      "Epoch 699/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1732 - val_loss: 0.1779\n",
      "Epoch 700/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1702 - val_loss: 0.1884\n",
      "Epoch 701/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1716 - val_loss: 0.1776\n",
      "Epoch 702/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1745 - val_loss: 0.1825\n",
      "Epoch 703/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1729 - val_loss: 0.1776\n",
      "Epoch 704/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1691 - val_loss: 0.1785\n",
      "Epoch 705/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1710 - val_loss: 0.1853\n",
      "Epoch 706/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1731 - val_loss: 0.1864\n",
      "Epoch 707/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1787 - val_loss: 0.1820\n",
      "Epoch 708/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1716 - val_loss: 0.1949\n",
      "Epoch 709/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1734 - val_loss: 0.1796\n",
      "Epoch 710/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1702 - val_loss: 0.1877\n",
      "Epoch 711/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1754 - val_loss: 0.1830\n",
      "Epoch 712/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1727 - val_loss: 0.1809\n",
      "Epoch 713/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1692 - val_loss: 0.1879\n",
      "Epoch 714/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1742 - val_loss: 0.1821\n",
      "Epoch 715/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1780 - val_loss: 0.2042\n",
      "Epoch 716/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1752 - val_loss: 0.1889\n",
      "Epoch 717/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1716 - val_loss: 0.1797\n",
      "Epoch 718/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1721 - val_loss: 0.1939\n",
      "Epoch 719/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1688 - val_loss: 0.1828\n",
      "Epoch 720/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1709 - val_loss: 0.1815\n",
      "Epoch 721/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1681 - val_loss: 0.1906\n",
      "Epoch 722/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1738 - val_loss: 0.1840\n",
      "Epoch 723/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1758 - val_loss: 0.1887\n",
      "Epoch 724/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1749 - val_loss: 0.1956\n",
      "Epoch 725/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1714 - val_loss: 0.1814\n",
      "Epoch 726/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1692 - val_loss: 0.1774\n",
      "Epoch 727/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1715 - val_loss: 0.1788\n",
      "Epoch 728/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1705 - val_loss: 0.1905\n",
      "Epoch 729/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1691 - val_loss: 0.1795\n",
      "Epoch 730/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1705 - val_loss: 0.1792\n",
      "Epoch 731/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1719 - val_loss: 0.1792\n",
      "Epoch 732/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1697 - val_loss: 0.1807\n",
      "Epoch 733/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1683 - val_loss: 0.1791\n",
      "Epoch 734/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1739 - val_loss: 0.1771\n",
      "Epoch 735/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1694 - val_loss: 0.1837\n",
      "Epoch 736/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1684 - val_loss: 0.1736\n",
      "Epoch 737/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1671 - val_loss: 0.1870\n",
      "Epoch 738/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1675 - val_loss: 0.1858\n",
      "Epoch 739/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1714 - val_loss: 0.1854\n",
      "Epoch 740/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1685 - val_loss: 0.1739\n",
      "Epoch 741/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1668 - val_loss: 0.1807\n",
      "Epoch 742/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1732 - val_loss: 0.1792\n",
      "Epoch 743/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1679 - val_loss: 0.1794\n",
      "Epoch 744/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1668 - val_loss: 0.1781\n",
      "Epoch 745/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1676 - val_loss: 0.1783\n",
      "Epoch 746/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1720 - val_loss: 0.1754\n",
      "Epoch 747/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1657 - val_loss: 0.1980\n",
      "Epoch 748/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1728 - val_loss: 0.1764\n",
      "Epoch 749/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1723 - val_loss: 0.1852\n",
      "Epoch 750/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1735 - val_loss: 0.1799\n",
      "Epoch 751/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1669 - val_loss: 0.1791\n",
      "Epoch 752/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1690 - val_loss: 0.1801\n",
      "Epoch 753/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1694 - val_loss: 0.1831\n",
      "Epoch 754/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1699 - val_loss: 0.1760\n",
      "Epoch 755/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1653 - val_loss: 0.1798\n",
      "Epoch 756/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1657 - val_loss: 0.1745\n",
      "Epoch 757/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1715 - val_loss: 0.1899\n",
      "Epoch 758/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1693 - val_loss: 0.1828\n",
      "Epoch 759/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1723 - val_loss: 0.1824\n",
      "Epoch 760/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1689 - val_loss: 0.1777\n",
      "Epoch 761/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1686 - val_loss: 0.1750\n",
      "Epoch 762/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1657 - val_loss: 0.1788\n",
      "Epoch 763/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1661 - val_loss: 0.1726\n",
      "Epoch 764/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1631 - val_loss: 0.1790\n",
      "Epoch 765/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1669 - val_loss: 0.1741\n",
      "Epoch 766/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1655 - val_loss: 0.1742\n",
      "Epoch 767/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1691 - val_loss: 0.1755\n",
      "Epoch 768/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1670 - val_loss: 0.1836\n",
      "Epoch 769/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1643 - val_loss: 0.1771\n",
      "Epoch 770/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1687 - val_loss: 0.1921\n",
      "Epoch 771/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1692 - val_loss: 0.1786\n",
      "Epoch 772/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1674 - val_loss: 0.1750\n",
      "Epoch 773/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1660 - val_loss: 0.1735\n",
      "Epoch 774/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1647 - val_loss: 0.1803\n",
      "Epoch 775/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1665 - val_loss: 0.1796\n",
      "Epoch 776/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1686 - val_loss: 0.1829\n",
      "Epoch 777/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1652 - val_loss: 0.1781\n",
      "Epoch 778/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1643 - val_loss: 0.1725\n",
      "Epoch 779/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1722 - val_loss: 0.1822\n",
      "Epoch 780/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1637 - val_loss: 0.1837\n",
      "Epoch 781/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1686 - val_loss: 0.1751\n",
      "Epoch 782/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1658 - val_loss: 0.1812\n",
      "Epoch 783/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1733 - val_loss: 0.1918\n",
      "Epoch 784/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1674 - val_loss: 0.1780\n",
      "Epoch 785/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1630 - val_loss: 0.1778\n",
      "Epoch 786/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1677 - val_loss: 0.1814\n",
      "Epoch 787/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1670 - val_loss: 0.1773\n",
      "Epoch 788/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1692 - val_loss: 0.1887\n",
      "Epoch 789/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1679 - val_loss: 0.1941\n",
      "Epoch 790/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1631 - val_loss: 0.1738\n",
      "Epoch 791/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1635 - val_loss: 0.1904\n",
      "Epoch 792/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1725 - val_loss: 0.1744\n",
      "Epoch 793/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1674 - val_loss: 0.1773\n",
      "Epoch 794/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1633 - val_loss: 0.1731\n",
      "Epoch 795/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1670 - val_loss: 0.2157\n",
      "Epoch 796/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1710 - val_loss: 0.1708\n",
      "Epoch 797/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1617 - val_loss: 0.1708\n",
      "Epoch 798/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1608 - val_loss: 0.1730\n",
      "Epoch 799/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1634 - val_loss: 0.1731\n",
      "Epoch 800/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1664 - val_loss: 0.1867\n",
      "Epoch 801/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1724 - val_loss: 0.1721\n",
      "Epoch 802/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1604 - val_loss: 0.1827\n",
      "Epoch 803/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1643 - val_loss: 0.1731\n",
      "Epoch 804/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1646 - val_loss: 0.1721\n",
      "Epoch 805/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1643 - val_loss: 0.1750\n",
      "Epoch 806/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1633 - val_loss: 0.1875\n",
      "Epoch 807/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1631 - val_loss: 0.1710\n",
      "Epoch 808/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1609 - val_loss: 0.1763\n",
      "Epoch 809/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1624 - val_loss: 0.1725\n",
      "Epoch 810/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1599 - val_loss: 0.1678\n",
      "Epoch 811/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1646 - val_loss: 0.1686\n",
      "Epoch 812/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1621 - val_loss: 0.1768\n",
      "Epoch 813/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1633 - val_loss: 0.1731\n",
      "Epoch 814/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1652 - val_loss: 0.1757\n",
      "Epoch 815/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1612 - val_loss: 0.1718\n",
      "Epoch 816/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1625 - val_loss: 0.1705\n",
      "Epoch 817/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1645 - val_loss: 0.1790\n",
      "Epoch 818/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1634 - val_loss: 0.1782\n",
      "Epoch 819/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1629 - val_loss: 0.1773\n",
      "Epoch 820/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1670 - val_loss: 0.1721\n",
      "Epoch 821/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1619 - val_loss: 0.1758\n",
      "Epoch 822/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1631 - val_loss: 0.1723\n",
      "Epoch 823/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1637 - val_loss: 0.1780\n",
      "Epoch 824/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1636 - val_loss: 0.1709\n",
      "Epoch 825/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1605 - val_loss: 0.1747\n",
      "Epoch 826/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1641 - val_loss: 0.1874\n",
      "Epoch 827/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1628 - val_loss: 0.1750\n",
      "Epoch 828/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1613 - val_loss: 0.1759\n",
      "Epoch 829/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1654 - val_loss: 0.1917\n",
      "Epoch 830/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1699 - val_loss: 0.1754\n",
      "Epoch 831/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1714 - val_loss: 0.1737\n",
      "Epoch 832/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1594 - val_loss: 0.1681\n",
      "Epoch 833/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1624 - val_loss: 0.1802\n",
      "Epoch 834/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1617 - val_loss: 0.1766\n",
      "Epoch 835/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1624 - val_loss: 0.1688\n",
      "Epoch 836/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1593 - val_loss: 0.1797\n",
      "Epoch 837/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1606 - val_loss: 0.1736\n",
      "Epoch 838/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1612 - val_loss: 0.1745\n",
      "Epoch 839/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1587 - val_loss: 0.1686\n",
      "Epoch 840/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1601 - val_loss: 0.1671\n",
      "Epoch 841/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1592 - val_loss: 0.1798\n",
      "Epoch 842/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1632 - val_loss: 0.1782\n",
      "Epoch 843/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1616 - val_loss: 0.1737\n",
      "Epoch 844/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1627 - val_loss: 0.1706\n",
      "Epoch 845/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1593 - val_loss: 0.1714\n",
      "Epoch 846/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1591 - val_loss: 0.1681\n",
      "Epoch 847/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1609 - val_loss: 0.1701\n",
      "Epoch 848/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1580 - val_loss: 0.1728\n",
      "Epoch 849/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1637 - val_loss: 0.1745\n",
      "Epoch 850/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1600 - val_loss: 0.1705\n",
      "Epoch 851/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1753\n",
      "Epoch 852/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1610 - val_loss: 0.1701\n",
      "Epoch 853/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1629 - val_loss: 0.1653\n",
      "Epoch 854/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1647 - val_loss: 0.1840\n",
      "Epoch 855/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1612 - val_loss: 0.1677\n",
      "Epoch 856/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1592 - val_loss: 0.1690\n",
      "Epoch 857/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1650 - val_loss: 0.1988\n",
      "Epoch 858/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1624 - val_loss: 0.1676\n",
      "Epoch 859/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1612 - val_loss: 0.1667\n",
      "Epoch 860/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1569 - val_loss: 0.1664\n",
      "Epoch 861/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1589 - val_loss: 0.1681\n",
      "Epoch 862/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1590 - val_loss: 0.1753\n",
      "Epoch 863/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1669 - val_loss: 0.1717\n",
      "Epoch 864/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1597 - val_loss: 0.1685\n",
      "Epoch 865/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1565 - val_loss: 0.1689\n",
      "Epoch 866/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1560 - val_loss: 0.1699\n",
      "Epoch 867/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1591 - val_loss: 0.1752\n",
      "Epoch 868/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1580 - val_loss: 0.1618\n",
      "Epoch 869/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1580 - val_loss: 0.1644\n",
      "Epoch 870/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1575 - val_loss: 0.1633\n",
      "Epoch 871/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1598 - val_loss: 0.1662\n",
      "Epoch 872/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1566 - val_loss: 0.1712\n",
      "Epoch 873/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1603 - val_loss: 0.1691\n",
      "Epoch 874/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1586 - val_loss: 0.1772\n",
      "Epoch 875/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1599 - val_loss: 0.1651\n",
      "Epoch 876/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1614 - val_loss: 0.1653\n",
      "Epoch 877/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1571 - val_loss: 0.1711\n",
      "Epoch 878/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1602 - val_loss: 0.1696\n",
      "Epoch 879/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1577 - val_loss: 0.1706\n",
      "Epoch 880/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1579 - val_loss: 0.1683\n",
      "Epoch 881/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1589 - val_loss: 0.1665\n",
      "Epoch 882/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1611 - val_loss: 0.1688\n",
      "Epoch 883/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1600 - val_loss: 0.1668\n",
      "Epoch 884/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1576 - val_loss: 0.1653\n",
      "Epoch 885/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1636 - val_loss: 0.1686\n",
      "Epoch 886/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1555 - val_loss: 0.1659\n",
      "Epoch 887/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1562 - val_loss: 0.1723\n",
      "Epoch 888/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1628 - val_loss: 0.1791\n",
      "Epoch 889/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1598 - val_loss: 0.1665\n",
      "Epoch 890/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1562 - val_loss: 0.1672\n",
      "Epoch 891/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1609 - val_loss: 0.1712\n",
      "Epoch 892/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1594 - val_loss: 0.1716\n",
      "Epoch 893/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1583 - val_loss: 0.1623\n",
      "Epoch 894/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1571 - val_loss: 0.1653\n",
      "Epoch 895/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1543 - val_loss: 0.1679\n",
      "Epoch 896/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1611 - val_loss: 0.1666\n",
      "Epoch 897/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1608 - val_loss: 0.1652\n",
      "Epoch 898/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1561 - val_loss: 0.1653\n",
      "Epoch 899/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1590 - val_loss: 0.1738\n",
      "Epoch 900/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1610 - val_loss: 0.1653\n",
      "Epoch 901/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1569 - val_loss: 0.1669\n",
      "Epoch 902/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1611 - val_loss: 0.1675\n",
      "Epoch 903/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1599 - val_loss: 0.1722\n",
      "Epoch 904/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1617 - val_loss: 0.1660\n",
      "Epoch 905/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1573 - val_loss: 0.1625\n",
      "Epoch 906/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1544 - val_loss: 0.1659\n",
      "Epoch 907/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1563 - val_loss: 0.1662\n",
      "Epoch 908/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1564 - val_loss: 0.1630\n",
      "Epoch 909/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1576 - val_loss: 0.1639\n",
      "Epoch 910/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1554 - val_loss: 0.1657\n",
      "Epoch 911/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1568 - val_loss: 0.1692\n",
      "Epoch 912/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1570 - val_loss: 0.1641\n",
      "Epoch 913/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1557 - val_loss: 0.1653\n",
      "Epoch 914/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1559 - val_loss: 0.1700\n",
      "Epoch 915/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1567 - val_loss: 0.1644\n",
      "Epoch 916/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1532 - val_loss: 0.1628\n",
      "Epoch 917/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1561 - val_loss: 0.1622\n",
      "Epoch 918/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1571 - val_loss: 0.1709\n",
      "Epoch 919/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1581 - val_loss: 0.1641\n",
      "Epoch 920/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1554 - val_loss: 0.1681\n",
      "Epoch 921/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1543 - val_loss: 0.1681\n",
      "Epoch 922/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1564 - val_loss: 0.1653\n",
      "Epoch 923/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1551 - val_loss: 0.1652\n",
      "Epoch 924/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1548 - val_loss: 0.1681\n",
      "Epoch 925/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1547 - val_loss: 0.1628\n",
      "Epoch 926/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1551 - val_loss: 0.1623\n",
      "Epoch 927/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1550 - val_loss: 0.1626\n",
      "Epoch 928/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1568 - val_loss: 0.1660\n",
      "Epoch 929/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1547 - val_loss: 0.1658\n",
      "Epoch 930/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1541 - val_loss: 0.1685\n",
      "Epoch 931/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1548 - val_loss: 0.1643\n",
      "Epoch 932/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1584 - val_loss: 0.1717\n",
      "Epoch 933/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1550 - val_loss: 0.1605\n",
      "Epoch 934/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1631 - val_loss: 0.1675\n",
      "Epoch 935/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1569 - val_loss: 0.1704\n",
      "Epoch 936/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1582 - val_loss: 0.1661\n",
      "Epoch 937/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1544 - val_loss: 0.1651\n",
      "Epoch 938/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1540 - val_loss: 0.1663\n",
      "Epoch 939/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1582 - val_loss: 0.1673\n",
      "Epoch 940/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1589 - val_loss: 0.1622\n",
      "Epoch 941/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1526 - val_loss: 0.1684\n",
      "Epoch 942/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1567 - val_loss: 0.1669\n",
      "Epoch 943/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1556 - val_loss: 0.1787\n",
      "Epoch 944/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1560 - val_loss: 0.1614\n",
      "Epoch 945/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1556 - val_loss: 0.1658\n",
      "Epoch 946/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1539 - val_loss: 0.1664\n",
      "Epoch 947/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1548 - val_loss: 0.1697\n",
      "Epoch 948/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1576 - val_loss: 0.1658\n",
      "Epoch 949/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1545 - val_loss: 0.1650\n",
      "Epoch 950/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1525 - val_loss: 0.1717\n",
      "Epoch 951/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1549 - val_loss: 0.1653\n",
      "Epoch 952/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1539 - val_loss: 0.1685\n",
      "Epoch 953/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1560 - val_loss: 0.1636\n",
      "Epoch 954/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1545 - val_loss: 0.1674\n",
      "Epoch 955/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1577 - val_loss: 0.1654\n",
      "Epoch 956/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1555 - val_loss: 0.1614\n",
      "Epoch 957/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1545 - val_loss: 0.1648\n",
      "Epoch 958/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1558 - val_loss: 0.1702\n",
      "Epoch 959/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1554 - val_loss: 0.1634\n",
      "Epoch 960/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1541 - val_loss: 0.1610\n",
      "Epoch 961/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1578 - val_loss: 0.1717\n",
      "Epoch 962/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1549 - val_loss: 0.1709\n",
      "Epoch 963/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1526 - val_loss: 0.1644\n",
      "Epoch 964/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1549 - val_loss: 0.1634\n",
      "Epoch 965/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1585 - val_loss: 0.1709\n",
      "Epoch 966/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1562 - val_loss: 0.1592\n",
      "Epoch 967/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1565 - val_loss: 0.1734\n",
      "Epoch 968/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1589 - val_loss: 0.1657\n",
      "Epoch 969/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1548 - val_loss: 0.1713\n",
      "Epoch 970/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1538 - val_loss: 0.1657\n",
      "Epoch 971/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1517 - val_loss: 0.1601\n",
      "Epoch 972/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1529 - val_loss: 0.1665\n",
      "Epoch 973/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1515 - val_loss: 0.1584\n",
      "Epoch 974/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1511 - val_loss: 0.1629\n",
      "Epoch 975/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1543 - val_loss: 0.1617\n",
      "Epoch 976/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1565 - val_loss: 0.1602\n",
      "Epoch 977/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1560 - val_loss: 0.1608\n",
      "Epoch 978/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1519 - val_loss: 0.1593\n",
      "Epoch 979/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1512 - val_loss: 0.1600\n",
      "Epoch 980/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1541 - val_loss: 0.1732\n",
      "Epoch 981/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1548 - val_loss: 0.1619\n",
      "Epoch 982/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1577 - val_loss: 0.1650\n",
      "Epoch 983/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1518 - val_loss: 0.1666\n",
      "Epoch 984/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1519 - val_loss: 0.1634\n",
      "Epoch 985/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1573 - val_loss: 0.1789\n",
      "Epoch 986/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1538 - val_loss: 0.1591\n",
      "Epoch 987/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1505 - val_loss: 0.1745\n",
      "Epoch 988/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1547 - val_loss: 0.1613\n",
      "Epoch 989/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1548 - val_loss: 0.1614\n",
      "Epoch 990/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1507 - val_loss: 0.1663\n",
      "Epoch 991/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1505 - val_loss: 0.1641\n",
      "Epoch 992/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1518 - val_loss: 0.1668\n",
      "Epoch 993/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1547 - val_loss: 0.1597\n",
      "Epoch 994/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1576 - val_loss: 0.1689\n",
      "Epoch 995/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1643 - val_loss: 0.1732\n",
      "Epoch 996/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1547 - val_loss: 0.1620\n",
      "Epoch 997/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1692\n",
      "Epoch 998/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1515 - val_loss: 0.1623\n",
      "Epoch 999/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1549 - val_loss: 0.1636\n",
      "Epoch 1000/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1528 - val_loss: 0.1581\n",
      "Epoch 1001/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1521 - val_loss: 0.1667\n",
      "Epoch 1002/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1543 - val_loss: 0.1610\n",
      "Epoch 1003/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1510 - val_loss: 0.1596\n",
      "Epoch 1004/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1521 - val_loss: 0.1594\n",
      "Epoch 1005/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1476 - val_loss: 0.1610\n",
      "Epoch 1006/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1523 - val_loss: 0.1645\n",
      "Epoch 1007/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1541 - val_loss: 0.1603\n",
      "Epoch 1008/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1507 - val_loss: 0.1595\n",
      "Epoch 1009/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1562 - val_loss: 0.1682\n",
      "Epoch 1010/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1520 - val_loss: 0.1654\n",
      "Epoch 1011/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1544 - val_loss: 0.1635\n",
      "Epoch 1012/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1517 - val_loss: 0.1660\n",
      "Epoch 1013/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1546 - val_loss: 0.1701\n",
      "Epoch 1014/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1622\n",
      "Epoch 1015/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1546 - val_loss: 0.1690\n",
      "Epoch 1016/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1534 - val_loss: 0.1589\n",
      "Epoch 1017/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1500 - val_loss: 0.1642\n",
      "Epoch 1018/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1509 - val_loss: 0.1669\n",
      "Epoch 1019/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1537 - val_loss: 0.1619\n",
      "Epoch 1020/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1487 - val_loss: 0.1592\n",
      "Epoch 1021/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1512 - val_loss: 0.1578\n",
      "Epoch 1022/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1499 - val_loss: 0.1578\n",
      "Epoch 1023/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1494 - val_loss: 0.1576\n",
      "Epoch 1024/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1521 - val_loss: 0.1629\n",
      "Epoch 1025/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1502 - val_loss: 0.1575\n",
      "Epoch 1026/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1506 - val_loss: 0.1620\n",
      "Epoch 1027/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1521 - val_loss: 0.1603\n",
      "Epoch 1028/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1495 - val_loss: 0.1676\n",
      "Epoch 1029/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1515 - val_loss: 0.1579\n",
      "Epoch 1030/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1536 - val_loss: 0.1604\n",
      "Epoch 1031/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1492 - val_loss: 0.1621\n",
      "Epoch 1032/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1552 - val_loss: 0.1606\n",
      "Epoch 1033/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1527 - val_loss: 0.1668\n",
      "Epoch 1034/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1546 - val_loss: 0.1614\n",
      "Epoch 1035/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.1641\n",
      "Epoch 1036/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1546 - val_loss: 0.1604\n",
      "Epoch 1037/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1580\n",
      "Epoch 1038/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1499 - val_loss: 0.1667\n",
      "Epoch 1039/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1519 - val_loss: 0.1579\n",
      "Epoch 1040/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1675\n",
      "Epoch 1041/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1541 - val_loss: 0.1593\n",
      "Epoch 1042/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1521 - val_loss: 0.1587\n",
      "Epoch 1043/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1512 - val_loss: 0.1561\n",
      "Epoch 1044/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1519 - val_loss: 0.1637\n",
      "Epoch 1045/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1507 - val_loss: 0.1652\n",
      "Epoch 1046/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1508 - val_loss: 0.1599\n",
      "Epoch 1047/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1536 - val_loss: 0.1575\n",
      "Epoch 1048/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1477 - val_loss: 0.1565\n",
      "Epoch 1049/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1507 - val_loss: 0.1736\n",
      "Epoch 1050/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1521 - val_loss: 0.1662\n",
      "Epoch 1051/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1558 - val_loss: 0.1604\n",
      "Epoch 1052/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1534 - val_loss: 0.1626\n",
      "Epoch 1053/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1570\n",
      "Epoch 1054/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1503 - val_loss: 0.1564\n",
      "Epoch 1055/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1730\n",
      "Epoch 1056/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1496 - val_loss: 0.1583\n",
      "Epoch 1057/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1565 - val_loss: 0.1554\n",
      "Epoch 1058/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1496 - val_loss: 0.1666\n",
      "Epoch 1059/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1489 - val_loss: 0.1616\n",
      "Epoch 1060/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1548 - val_loss: 0.1695\n",
      "Epoch 1061/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1505 - val_loss: 0.1641\n",
      "Epoch 1062/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.1608\n",
      "Epoch 1063/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1487 - val_loss: 0.1585\n",
      "Epoch 1064/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1566\n",
      "Epoch 1065/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1495 - val_loss: 0.1583\n",
      "Epoch 1066/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1491 - val_loss: 0.1575\n",
      "Epoch 1067/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1489 - val_loss: 0.1554\n",
      "Epoch 1068/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1486 - val_loss: 0.1552\n",
      "Epoch 1069/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1493 - val_loss: 0.1591\n",
      "Epoch 1070/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1506 - val_loss: 0.1585\n",
      "Epoch 1071/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1518 - val_loss: 0.1598\n",
      "Epoch 1072/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1524 - val_loss: 0.1612\n",
      "Epoch 1073/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1506 - val_loss: 0.1590\n",
      "Epoch 1074/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1488 - val_loss: 0.1589\n",
      "Epoch 1075/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1483 - val_loss: 0.1543\n",
      "Epoch 1076/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1488 - val_loss: 0.1636\n",
      "Epoch 1077/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1522 - val_loss: 0.1627\n",
      "Epoch 1078/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1546 - val_loss: 0.1678\n",
      "Epoch 1079/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1502 - val_loss: 0.1645\n",
      "Epoch 1080/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1500 - val_loss: 0.1618\n",
      "Epoch 1081/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1539 - val_loss: 0.1674\n",
      "Epoch 1082/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1503 - val_loss: 0.1608\n",
      "Epoch 1083/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1476 - val_loss: 0.1592\n",
      "Epoch 1084/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1507 - val_loss: 0.1690\n",
      "Epoch 1085/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1522 - val_loss: 0.1604\n",
      "Epoch 1086/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1506 - val_loss: 0.1576\n",
      "Epoch 1087/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1505 - val_loss: 0.1567\n",
      "Epoch 1088/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1489 - val_loss: 0.1561\n",
      "Epoch 1089/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1513 - val_loss: 0.1596\n",
      "Epoch 1090/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1549 - val_loss: 0.1589\n",
      "Epoch 1091/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1556\n",
      "Epoch 1092/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1489 - val_loss: 0.1590\n",
      "Epoch 1093/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1499 - val_loss: 0.1687\n",
      "Epoch 1094/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1516 - val_loss: 0.1592\n",
      "Epoch 1095/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1511 - val_loss: 0.1588\n",
      "Epoch 1096/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1488 - val_loss: 0.1584\n",
      "Epoch 1097/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1473 - val_loss: 0.1666\n",
      "Epoch 1098/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1486 - val_loss: 0.1671\n",
      "Epoch 1099/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1517 - val_loss: 0.1593\n",
      "Epoch 1100/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1524 - val_loss: 0.1583\n",
      "Epoch 1101/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1670\n",
      "Epoch 1102/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1512 - val_loss: 0.1573\n",
      "Epoch 1103/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1497 - val_loss: 0.1577\n",
      "Epoch 1104/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1489 - val_loss: 0.1566\n",
      "Epoch 1105/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1460 - val_loss: 0.1572\n",
      "Epoch 1106/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1494 - val_loss: 0.1566\n",
      "Epoch 1107/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1470 - val_loss: 0.1685\n",
      "Epoch 1108/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1512 - val_loss: 0.1571\n",
      "Epoch 1109/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1501 - val_loss: 0.1567\n",
      "Epoch 1110/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1488 - val_loss: 0.1545\n",
      "Epoch 1111/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1499 - val_loss: 0.1688\n",
      "Epoch 1112/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1533 - val_loss: 0.1560\n",
      "Epoch 1113/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1482 - val_loss: 0.1547\n",
      "Epoch 1114/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1499 - val_loss: 0.1592\n",
      "Epoch 1115/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1456 - val_loss: 0.1592\n",
      "Epoch 1116/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1479 - val_loss: 0.1575\n",
      "Epoch 1117/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1535 - val_loss: 0.1715\n",
      "Epoch 1118/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1507 - val_loss: 0.1610\n",
      "Epoch 1119/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1472 - val_loss: 0.1591\n",
      "Epoch 1120/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1525 - val_loss: 0.1717\n",
      "Epoch 1121/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1531 - val_loss: 0.1588\n",
      "Epoch 1122/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1497 - val_loss: 0.1587\n",
      "Epoch 1123/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1505 - val_loss: 0.1561\n",
      "Epoch 1124/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1542 - val_loss: 0.1581\n",
      "Epoch 1125/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1504 - val_loss: 0.1597\n",
      "Epoch 1126/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1488 - val_loss: 0.1563\n",
      "Epoch 1127/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1485 - val_loss: 0.1588\n",
      "Epoch 1128/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1474 - val_loss: 0.1590\n",
      "Epoch 1129/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1494 - val_loss: 0.1595\n",
      "Epoch 1130/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1477 - val_loss: 0.1573\n",
      "Epoch 1131/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1481 - val_loss: 0.1561\n",
      "Epoch 1132/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1462 - val_loss: 0.1550\n",
      "Epoch 1133/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1443 - val_loss: 0.1556\n",
      "Epoch 1134/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1492 - val_loss: 0.1578\n",
      "Epoch 1135/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1487 - val_loss: 0.1595\n",
      "Epoch 1136/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1487 - val_loss: 0.1575\n",
      "Epoch 1137/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1497 - val_loss: 0.1563\n",
      "Epoch 1138/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1492 - val_loss: 0.1592\n",
      "Epoch 1139/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1468 - val_loss: 0.1580\n",
      "Epoch 1140/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1482 - val_loss: 0.1581\n",
      "Epoch 1141/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1483 - val_loss: 0.1587\n",
      "Epoch 1142/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1479 - val_loss: 0.1549\n",
      "Epoch 1143/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1480 - val_loss: 0.1614\n",
      "Epoch 1144/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1497 - val_loss: 0.1560\n",
      "Epoch 1145/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1505 - val_loss: 0.1574\n",
      "Epoch 1146/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1507 - val_loss: 0.1606\n",
      "Epoch 1147/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1487 - val_loss: 0.1578\n",
      "Epoch 1148/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1479 - val_loss: 0.1566\n",
      "Epoch 1149/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1480 - val_loss: 0.1546\n",
      "Epoch 1150/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1505 - val_loss: 0.1577\n",
      "Epoch 1151/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1497 - val_loss: 0.1566\n",
      "Epoch 1152/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1479 - val_loss: 0.1619\n",
      "Epoch 1153/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1471 - val_loss: 0.1537\n",
      "Epoch 1154/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1465 - val_loss: 0.1550\n",
      "Epoch 1155/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1483 - val_loss: 0.1579\n",
      "Epoch 1156/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1483 - val_loss: 0.1575\n",
      "Epoch 1157/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1471 - val_loss: 0.1649\n",
      "Epoch 1158/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1481 - val_loss: 0.1590\n",
      "Epoch 1159/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1481 - val_loss: 0.1593\n",
      "Epoch 1160/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1492 - val_loss: 0.1574\n",
      "Epoch 1161/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1486 - val_loss: 0.1562\n",
      "Epoch 1162/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1470 - val_loss: 0.1574\n",
      "Epoch 1163/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1503 - val_loss: 0.1573\n",
      "Epoch 1164/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1551 - val_loss: 0.1548\n",
      "Epoch 1165/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1478 - val_loss: 0.1558\n",
      "Epoch 1166/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1470 - val_loss: 0.1652\n",
      "Epoch 1167/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1512 - val_loss: 0.1562\n",
      "Epoch 1168/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1481 - val_loss: 0.1561\n",
      "Epoch 1169/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1462 - val_loss: 0.1547\n",
      "Epoch 1170/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1478 - val_loss: 0.1560\n",
      "Epoch 1171/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1469 - val_loss: 0.1549\n",
      "Epoch 1172/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1488 - val_loss: 0.1555\n",
      "Epoch 1173/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1453 - val_loss: 0.1556\n",
      "Epoch 1174/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1479 - val_loss: 0.1594\n",
      "Epoch 1175/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1479 - val_loss: 0.1510\n",
      "Epoch 1176/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1472 - val_loss: 0.1591\n",
      "Epoch 1177/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1455 - val_loss: 0.1557\n",
      "Epoch 1178/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1495 - val_loss: 0.1562\n",
      "Epoch 1179/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1479 - val_loss: 0.1588\n",
      "Epoch 1180/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1536 - val_loss: 0.1532\n",
      "Epoch 1181/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1471 - val_loss: 0.1611\n",
      "Epoch 1182/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1504 - val_loss: 0.1577\n",
      "Epoch 1183/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1472 - val_loss: 0.1626\n",
      "Epoch 1184/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1514 - val_loss: 0.1604\n",
      "Epoch 1185/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1502 - val_loss: 0.1574\n",
      "Epoch 1186/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1470 - val_loss: 0.1538\n",
      "Epoch 1187/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1465 - val_loss: 0.1555\n",
      "Epoch 1188/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1479 - val_loss: 0.1555\n",
      "Epoch 1189/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1458 - val_loss: 0.1556\n",
      "Epoch 1190/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1453 - val_loss: 0.1609\n",
      "Epoch 1191/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1467 - val_loss: 0.1577\n",
      "Epoch 1192/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1491 - val_loss: 0.1573\n",
      "Epoch 1193/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1472 - val_loss: 0.1703\n",
      "Epoch 1194/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1500 - val_loss: 0.1553\n",
      "Epoch 1195/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1478 - val_loss: 0.1544\n",
      "Epoch 1196/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1497 - val_loss: 0.1571\n",
      "Epoch 1197/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1467 - val_loss: 0.1572\n",
      "Epoch 1198/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1504 - val_loss: 0.1519\n",
      "Epoch 1199/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1465 - val_loss: 0.1572\n",
      "Epoch 1200/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1438 - val_loss: 0.1512\n",
      "Epoch 1201/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1475 - val_loss: 0.1664\n",
      "Epoch 1202/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1460 - val_loss: 0.1609\n",
      "Epoch 1203/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1496 - val_loss: 0.1645\n",
      "Epoch 1204/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1523 - val_loss: 0.1517\n",
      "Epoch 1205/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1458 - val_loss: 0.1539\n",
      "Epoch 1206/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1466 - val_loss: 0.1562\n",
      "Epoch 1207/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1472 - val_loss: 0.1516\n",
      "Epoch 1208/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1485 - val_loss: 0.1609\n",
      "Epoch 1209/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1492 - val_loss: 0.1565\n",
      "Epoch 1210/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1461 - val_loss: 0.1549\n",
      "Epoch 1211/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1454 - val_loss: 0.1492\n",
      "Epoch 1212/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1456 - val_loss: 0.1523\n",
      "Epoch 1213/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1477 - val_loss: 0.1598\n",
      "Epoch 1214/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1485 - val_loss: 0.1508\n",
      "Epoch 1215/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1463 - val_loss: 0.1567\n",
      "Epoch 1216/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1464 - val_loss: 0.1554\n",
      "Epoch 1217/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1492 - val_loss: 0.1544\n",
      "Epoch 1218/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1481 - val_loss: 0.1567\n",
      "Epoch 1219/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1476 - val_loss: 0.1568\n",
      "Epoch 1220/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1480 - val_loss: 0.1640\n",
      "Epoch 1221/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1455 - val_loss: 0.1578\n",
      "Epoch 1222/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1490 - val_loss: 0.1521\n",
      "Epoch 1223/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1446 - val_loss: 0.1550\n",
      "Epoch 1224/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1475 - val_loss: 0.1573\n",
      "Epoch 1225/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1467 - val_loss: 0.1563\n",
      "Epoch 1226/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1500 - val_loss: 0.1624\n",
      "Epoch 1227/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1520 - val_loss: 0.1583\n",
      "Epoch 1228/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1451 - val_loss: 0.1534\n",
      "Epoch 1229/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1462 - val_loss: 0.1614\n",
      "Epoch 1230/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1469 - val_loss: 0.1713\n",
      "Epoch 1231/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1504 - val_loss: 0.1787\n",
      "Epoch 1232/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1461 - val_loss: 0.1561\n",
      "Epoch 1233/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1445 - val_loss: 0.1535\n",
      "Epoch 1234/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1446 - val_loss: 0.1560\n",
      "Epoch 1235/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1473 - val_loss: 0.1527\n",
      "Epoch 1236/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1459 - val_loss: 0.1597\n",
      "Epoch 1237/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1485 - val_loss: 0.1612\n",
      "Epoch 1238/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1476 - val_loss: 0.1544\n",
      "Epoch 1239/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1474 - val_loss: 0.1623\n",
      "Epoch 1240/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1483 - val_loss: 0.1533\n",
      "Epoch 1241/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1414 - val_loss: 0.1646\n",
      "Epoch 1242/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1458 - val_loss: 0.1542\n",
      "Epoch 1243/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1488 - val_loss: 0.1629\n",
      "Epoch 1244/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1473 - val_loss: 0.1517\n",
      "Epoch 1245/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1463 - val_loss: 0.1543\n",
      "Epoch 1246/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1457 - val_loss: 0.1524\n",
      "Epoch 1247/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1438 - val_loss: 0.1556\n",
      "Epoch 1248/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1499 - val_loss: 0.1531\n",
      "Epoch 1249/1250\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1483 - val_loss: 0.1580\n",
      "Epoch 1250/1250\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 0.1471 - val_loss: 0.1536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f26e3019270>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss=rmse)\n",
    "model.fit(x, y, epochs = 1250, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f26d860d390>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(x)\n",
    "\n",
    "n=np.linspace(10, 13.5, 100)\n",
    "\n",
    "plt.scatter(y_pred, y)\n",
    "plt.plot(n, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(submission)\n",
    "y_pred = np.exp(y_pred)\n",
    "y_pred = y_pred.reshape(-1)\n",
    "\n",
    "n = np.linspace(1461, 2919, 1459, dtype='int')\n",
    "\n",
    "df = pd.DataFrame({'Id':n, 'SalePrice':y_pred})\n",
    "\n",
    "# df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
